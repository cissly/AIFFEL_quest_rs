{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73e22801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "import sentencepiece as spm\n",
    "\n",
    "import math\n",
    "import os\n",
    "import re\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661c176c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, position, d_model):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.position = position\n",
    "\n",
    "        self.pos_encoding = self._build_pos_encoding(position, d_model)\n",
    "\n",
    "    def _get_angles(self, position, i, d_model):\n",
    "        return 1.0 / (10000.0 ** ((2.0 * (i // 2)) / d_model)) * position\n",
    "\n",
    "    def _build_pos_encoding(self, position, d_model):\n",
    "        pos = torch.arange(position, dtype=torch.float32).unsqueeze(1)\n",
    "        i = torch.arange(d_model, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "        angle_rads = self._get_angles(pos, i, d_model)\n",
    "        sines = torch.sin(angle_rads[:, 0::2])\n",
    "        cosines = torch.cos(angle_rads[:, 1::2])\n",
    "\n",
    "        pos_encoding = torch.zeros(position, d_model)\n",
    "        pos_encoding[:, 0::2] = sines\n",
    "        pos_encoding[:, 1::2] = cosines\n",
    "\n",
    "        pos_encoding = pos_encoding.unsqueeze(0)  # shape: [1, position, d_model]\n",
    "        return pos_encoding\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pos_encoding[:, :x.size(1), :].to(x.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8792aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(query, key, value, mask=None):\n",
    "\n",
    "    # 1) Q와 K의 내적을 통해 score(유사도) 계산\n",
    "    # key.transpose(-1, -2): (batch_size, heads, depth, seq_len)\n",
    "    # matmul 결과 shape: (batch_size, heads, seq_len, seq_len)\n",
    "    matmul_qk = torch.matmul(query, key.transpose(-1, -2))\n",
    "\n",
    "    # 2) depth에 따라 정규화\n",
    "    depth = key.size(-1)  # depth = d_model / heads\n",
    "    logits = matmul_qk / math.sqrt(depth)\n",
    "\n",
    "    # 3) 마스크가 주어졌다면 -1e9(아주 작은 값)를 더해 소프트맥스에서 제외시키도록 함\n",
    "    if mask is not None:\n",
    "        # 텐서플로우: logits += (mask * -1e9)\n",
    "        # 파이토치 동일 적용\n",
    "        logits = logits + (mask * -1e9)\n",
    "\n",
    "    # 4) 소프트맥스 계산해 attention weights 생성\n",
    "    attention_weights = F.softmax(logits, dim=-1)\n",
    "\n",
    "    # 5) attention weights와 value의 내적\n",
    "    output = torch.matmul(attention_weights, value)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "beff45d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, name=\"multi_head_attention\"):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # d_model은 num_heads로 나누어떨어져야 함\n",
    "        assert d_model % num_heads == 0\n",
    "\n",
    "        self.depth = d_model // num_heads\n",
    "\n",
    "        # 파이토치에서 Dense는 nn.Linear로 대응\n",
    "        self.query_dense = nn.Linear(d_model, d_model)\n",
    "        self.key_dense = nn.Linear(d_model, d_model)\n",
    "        self.value_dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "        self.out_dense = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"\n",
    "        x: (batch_size, seq_len, d_model)\n",
    "        => (batch_size, num_heads, seq_len, depth) 형태로 변환\n",
    "        \"\"\"\n",
    "        x = x.view(batch_size, -1, self.num_heads, self.depth)\n",
    "        x = x.permute(0, 2, 1, 3)  # (batch_size, num_heads, seq_len, depth)\n",
    "        return x\n",
    "\n",
    "    def forward(self, query, key, value, mask=None):\n",
    "        \"\"\"\n",
    "        query, key, value: (batch_size, seq_len, d_model)\n",
    "        mask: (batch_size, 1, seq_len, seq_len) 등으로 broadcast 가능하도록 구성\n",
    "        \"\"\"\n",
    "        batch_size = query.size(0)\n",
    "\n",
    "        # Q, K, V에 각각 Linear 적용\n",
    "        query = self.query_dense(query)\n",
    "        key = self.key_dense(key)\n",
    "        value = self.value_dense(value)\n",
    "\n",
    "        # Head 분할\n",
    "        query = self.split_heads(query, batch_size)\n",
    "        key = self.split_heads(key, batch_size)\n",
    "        value = self.split_heads(value, batch_size)\n",
    "\n",
    "        # 스케일드 닷 프로덕트 어텐션\n",
    "        scaled_attention, _ = scaled_dot_product_attention(query, key, value, mask)\n",
    "\n",
    "        # (batch_size, num_heads, seq_len, depth) -> (batch_size, seq_len, num_heads, depth)\n",
    "        scaled_attention = scaled_attention.permute(0, 2, 1, 3).contiguous()\n",
    "\n",
    "        # 다시 (batch_size, seq_len, d_model)로 합치기\n",
    "        concat_attention = scaled_attention.view(batch_size, -1, self.d_model)\n",
    "\n",
    "        # 최종 Dense\n",
    "        output = self.out_dense(concat_attention)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09030be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.mha = MultiHeadAttention(d_model, num_heads)  # 이전에 구현한 MHA\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 피드포워드 부분 (Dense -> ReLU -> Dense)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, d_model)\n",
    "        )\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # (1) 멀티 헤드 어텐션 (셀프 어텐션)\n",
    "        attn_output = self.mha(x, x, x, mask)  # (batch_size, seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.norm1(x + attn_output)     # 잔차 연결 + LayerNorm\n",
    "\n",
    "        # (2) 피드포워드 신경망\n",
    "        ffn_output = self.ffn(out1)            # (batch_size, seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out2 = self.norm2(out1 + ffn_output)   # 잔차 연결 + LayerNorm\n",
    "\n",
    "        return out2\n",
    "    \n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 ff_dim,\n",
    "                 d_model,\n",
    "                 num_heads,\n",
    "                 dropout=0.1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # (1) 임베딩 레이어\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩\n",
    "        self.pos_encoding = PositionalEncoding(position=vocab_size, d_model=d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # (3) EncoderLayer 쌓기\n",
    "        self.enc_layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # (1) 임베딩 & sqrt(d_model)로 스케일링\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩 적용 + 드롭아웃\n",
    "        x = self.pos_encoding(x)  # shape: (batch_size, seq_len, d_model)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # (3) num_layers만큼 쌓아올린 EncoderLayer 통과\n",
    "        for layer in self.enc_layers:\n",
    "            x = layer(x, mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf0dbd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, ff_dim, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        # 첫 번째 서브 레이어 (디코더 내부 셀프 어텐션)\n",
    "        self.self_mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm1 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 두 번째 서브 레이어 (인코더-디코더 어텐션)\n",
    "        self.encdec_mha = MultiHeadAttention(d_model, num_heads)\n",
    "        self.norm2 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 세 번째 서브 레이어 (피드포워드 네트워크)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(d_model, ff_dim),  # Dense(units=ff_dim)\n",
    "            nn.ReLU(),                   # activation='relu'\n",
    "            nn.Linear(ff_dim, d_model)   # Dense(units=d_model)\n",
    "        )\n",
    "        self.norm3 = nn.LayerNorm(d_model, eps=1e-6)\n",
    "\n",
    "        # 드롭아웃\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, enc_outputs, look_ahead_mask=None, padding_mask=None):\n",
    "        # 1) 셀프 어텐션 (디코더 내부)\n",
    "        self_attn_out = self.self_mha(x, x, x, mask=look_ahead_mask)\n",
    "        self_attn_out = self.dropout1(self_attn_out)\n",
    "        out1 = self.norm1(x + self_attn_out)  # 잔차 연결 + LayerNorm\n",
    "\n",
    "        # 2) 인코더-디코더 어텐션\n",
    "        encdec_attn_out = self.encdec_mha(out1, enc_outputs, enc_outputs, mask=padding_mask)\n",
    "        encdec_attn_out = self.dropout2(encdec_attn_out)\n",
    "        out2 = self.norm2(out1 + encdec_attn_out)  # 잔차 연결 + LayerNorm\n",
    "\n",
    "        # 3) 피드포워드 (Dense -> ReLU -> Dense)\n",
    "        ffn_out = self.ffn(out2)\n",
    "        ffn_out = self.dropout3(ffn_out)\n",
    "        out3 = self.norm3(out2 + ffn_out)  # 잔차 연결 + LayerNorm\n",
    "\n",
    "        return out3\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,\n",
    "                 ff_dim,\n",
    "                 d_model,\n",
    "                 num_heads,\n",
    "                 dropout=0.1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        # (1) 임베딩 레이어\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩\n",
    "        # 실제 학습 시에는 최대 시퀀스 길이에 맞추어 쓰기도 함\n",
    "        self.pos_encoding = PositionalEncoding(position=vocab_size, d_model=d_model)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        # (3) DecoderLayer 쌓기\n",
    "        self.dec_layers = nn.ModuleList([\n",
    "            DecoderLayer(d_model, num_heads, ff_dim, dropout)\n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, enc_outputs, look_ahead_mask=None, padding_mask=None):\n",
    "        # (1) 임베딩 + sqrt(d_model)로 스케일링\n",
    "        x = self.embedding(x) * math.sqrt(self.d_model)\n",
    "\n",
    "        # (2) 포지셔널 인코딩 + 드롭아웃\n",
    "        x = self.pos_encoding(x)    # (batch_size, tgt_seq_len, d_model)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # (3) num_layers만큼 쌓인 DecoderLayer 통과\n",
    "        for layer in self.dec_layers:\n",
    "            x = layer(x, enc_outputs, look_ahead_mask, padding_mask)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bedd36d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Q           A\n",
      "0            12시 땡   하루가 또 가네요\n",
      "1      1지망 학교 떨어졌어    위로해 드립니다\n",
      "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠\n",
      "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠\n",
      "4              심하네   눈살이 찌푸려지죠\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"C:\\\\Users\\\\tkdwl\\\\AIFFEL_quest_rs\\\\Exploration\\\\Ex07\\\\datas\\\\ChatbotData.csv\")\n",
    "data.drop([\"label\"], axis=1,inplace=True)\n",
    "\n",
    "def clean_korean(text):\n",
    "    # 한글, 공백만 남기기\n",
    "    text = re.sub(r'[^가-힣0-9\\s]', '', str(text))\n",
    "    # 연속 공백 제거\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Q, A 컬럼 전처리\n",
    "data['Q'] = data['Q'].apply(clean_korean)\n",
    "data['A'] = data['A'].apply(clean_korean)\n",
    "\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cb8a0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 후의 문장: 3박4일 정도 놀러가고 싶다\n",
      "Tokenized: ['▁3', '박', '4', '일', '▁정도', '▁놀러가고', '▁싶다']\n",
      "Encoded: [470, 11295, 11263, 10840, 979, 3482, 198]\n",
      "Decoded: 3박4일 정도 놀러가고 싶다\n"
     ]
    }
   ],
   "source": [
    "corpus_file = \"clean_corpus.txt\"\n",
    "with open(corpus_file, 'w', encoding='utf-8') as f:\n",
    "    for q, a in zip(data[\"Q\"], data[\"A\"]):\n",
    "        f.write(q + \"\\n\")\n",
    "        f.write(a + \"\\n\")\n",
    "\n",
    "vocab_size = 12000\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    input=corpus_file,\n",
    "    model_prefix=\"korean_chatbot_spm\",\n",
    "    vocab_size=vocab_size,\n",
    "    character_coverage=1.0,\n",
    "    model_type=\"bpe\",\n",
    "    max_sentence_length=999999,\n",
    "    bos_id=1,  # <s> (Beginning of Sentence) 설정\n",
    "    eos_id=2,  # </s> (End of Sentence) 설정\n",
    "    pad_id=0,  # Padding ID 설정\n",
    "    unk_id=3   # Unknown Token ID 설정\n",
    ")\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.Load(\"korean_chatbot_spm.model\")\n",
    "\n",
    "# 예제 문장\n",
    "sentence = \" 3박4일 정도 놀러가고 싶다\"\n",
    "\n",
    "sentence = clean_korean(sentence)\n",
    "print(\"전처리 후의 문장:\", sentence)\n",
    "\n",
    "# 1. 토크나이징 (subword 단위로 분할)\n",
    "tokens = sp.encode(sentence, out_type=str)\n",
    "print(\"Tokenized:\", tokens)\n",
    "\n",
    "# 2. 인코딩 (서브워드를 정수 ID로 변환)\n",
    "encoded = sp.encode(sentence, out_type=int)\n",
    "print(\"Encoded:\", encoded)\n",
    "\n",
    "# 3. 디코딩 (정수 ID → 원본 문장 복원)\n",
    "decoded = sp.decode(encoded)\n",
    "print(\"Decoded:\", decoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f541bc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KoDataset(Dataset):\n",
    "    def __init__(self, pairs, sp, max_length=40):\n",
    "        super().__init__()\n",
    "        self.sp = sp\n",
    "        self.max_length = max_length\n",
    "        self.data = []\n",
    "\n",
    "        for q_text, a_text in pairs:\n",
    "            # 1) 토크나이즈\n",
    "            q_ids = sp.EncodeAsIds(q_text)\n",
    "            a_ids = sp.EncodeAsIds(a_text)\n",
    "\n",
    "            # 2) [CLS]/[SEP] 같은 별도 스페셜 토큰을 쓸 수도 있으나,\n",
    "            #    여기서는 SentencePiece 기본 <s>, </s> 등 혹은 사용자 정의 토큰 활용 가능\n",
    "            #    간단히 <s>=sp.bos_id(), </s>=sp.eos_id()로 가정해본다면:\n",
    "            #    sp.SetEncodeExtraOptions(\"bos:eos\") 등으로 설정하는 방법도 있음.\n",
    "            # 여기서는 수동으로 bos/eos id를 붙인다고 가정\n",
    "            bos_id = sp.bos_id() if sp.bos_id() >= 0 else 1  # 혹은 임의값\n",
    "            eos_id = sp.eos_id() if sp.eos_id() >= 0 else 2\n",
    "\n",
    "            q_tokens = [bos_id] + q_ids + [eos_id]\n",
    "            a_tokens = [bos_id] + a_ids + [eos_id]\n",
    "\n",
    "            # 3) 길이 제한\n",
    "            if len(q_tokens) > max_length or len(a_tokens) > max_length:\n",
    "                continue\n",
    "\n",
    "            # 4) 고정 길이 패딩\n",
    "            q_tokens += [0]*(max_length - len(q_tokens))  # 0 -> <pad> 가정\n",
    "            a_tokens += [0]*(max_length - len(a_tokens))\n",
    "\n",
    "            # 5) 디코더 입력(dec_input): a_tokens[:-1], 타겟(outputs): a_tokens[1:]\n",
    "            #    (teacher forcing용)\n",
    "            dec_input = a_tokens[:-1]\n",
    "            target = a_tokens[1:]\n",
    "\n",
    "            self.data.append({\n",
    "                \"enc_input\": q_tokens,\n",
    "                \"dec_input\": dec_input,\n",
    "                \"target\": target\n",
    "            })\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        enc_input = torch.tensor(sample[\"enc_input\"], dtype=torch.long)\n",
    "        dec_input = torch.tensor(sample[\"dec_input\"], dtype=torch.long)\n",
    "        target = torch.tensor(sample[\"target\"], dtype=torch.long)\n",
    "        return enc_input, dec_input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5954810f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 vocab_size,\n",
    "                 num_layers,      # 인코더/디코더 층 수\n",
    "                 units,           # feed-forward 네트워크의 중간 차원(ff_dim)\n",
    "                 d_model,         # 임베딩 및 내부 표현 차원\n",
    "                 num_heads,       # 멀티헤드 어텐션의 헤드 수\n",
    "                 dropout=0.1):\n",
    "        super(Transformer, self).__init__()\n",
    "\n",
    "        # 인코더\n",
    "        self.encoder = Encoder(\n",
    "            vocab_size=vocab_size,\n",
    "            num_layers=num_layers,\n",
    "            ff_dim=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # 디코더\n",
    "        self.decoder = Decoder(\n",
    "            vocab_size=vocab_size,\n",
    "            num_layers=num_layers,\n",
    "            ff_dim=units,\n",
    "            d_model=d_model,\n",
    "            num_heads=num_heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "\n",
    "        # 최종 출력층: (d_model) -> (vocab_size)\n",
    "        self.final_linear = nn.Linear(d_model, vocab_size)\n",
    "\n",
    "        # 참고: 텐서플로우 코드의 `name=\"transformer\"`는 파이토치에선 보통 사용 안 함\n",
    "    def create_padding_mask(self, x):\n",
    "        # x == 0 위치를 찾아 float형 1로 변환\n",
    "        mask = (x == 0).float()\n",
    "        # (batch_size, seq_len) -> (batch_size, 1, 1, seq_len)\n",
    "        mask = mask.unsqueeze(1).unsqueeze(2)\n",
    "        return mask\n",
    "    def create_look_ahead_mask(self, x):\n",
    "        seq_len = x.size(1)\n",
    "\n",
    "        # (seq_len, seq_len) 크기의 하삼각 행렬(tril) 생성 후 1에서 빼서\n",
    "        # 상삼각이 1, 하삼각(자기 자신 포함)이 0이 되도록 설정\n",
    "        # => 미래 토큰(자신 인덱스보다 큰 위치) 마스킹\n",
    "        look_ahead_mask = 1 - torch.tril(torch.ones((seq_len, seq_len)))\n",
    "\n",
    "        # 패딩 마스크 생성 (shape: (batch_size, 1, 1, seq_len))\n",
    "        padding_mask = self.create_padding_mask(x)\n",
    "\n",
    "        # look_ahead_mask: (seq_len, seq_len) -> (1, seq_len, seq_len)\n",
    "        look_ahead_mask = look_ahead_mask.unsqueeze(0)\n",
    "        # -> (1, seq_len, seq_len) -> (1, 1, seq_len, seq_len)\n",
    "        look_ahead_mask = look_ahead_mask.unsqueeze(1)\n",
    "        look_ahead_mask = look_ahead_mask.to(x.device)\n",
    "\n",
    "        # look-ahead 마스크와 패딩 마스크를 합성 (둘 중 하나라도 1이면 마스킹)\n",
    "        # 최종 shape은 브로드캐스팅으로 (batch_size, 1, seq_len, seq_len)\n",
    "        combined_mask = torch.max(look_ahead_mask, padding_mask)\n",
    "        return combined_mask\n",
    "    \n",
    "    def forward(self, inputs, dec_inputs):\n",
    "        # 1) 인코더 패딩 마스크 생성\n",
    "        enc_padding_mask = self.create_padding_mask(inputs)     # shape (batch_size, 1, 1, src_seq_len)\n",
    "\n",
    "        # 2) 디코더 look-ahead + 패딩 마스크\n",
    "        look_ahead_mask = self.create_look_ahead_mask(dec_inputs)  # shape (batch_size, 1, tgt_seq_len, tgt_seq_len)\n",
    "\n",
    "        # 3) 디코더에서 인코더 출력 쪽을 마스킹할 때 쓸 패딩 마스크\n",
    "        dec_padding_mask = self.create_padding_mask(inputs)        # shape (batch_size, 1, 1, src_seq_len)\n",
    "\n",
    "        # 4) 인코더 수행\n",
    "        enc_outputs = self.encoder(\n",
    "            x=inputs,\n",
    "            mask=enc_padding_mask\n",
    "        )  # shape: (batch_size, src_seq_len, d_model)\n",
    "\n",
    "        # 5) 디코더 수행\n",
    "        dec_outputs = self.decoder(\n",
    "            x=dec_inputs,           # (batch_size, tgt_seq_len)\n",
    "            enc_outputs=enc_outputs,# (batch_size, src_seq_len, d_model)\n",
    "            look_ahead_mask=look_ahead_mask,\n",
    "            padding_mask=dec_padding_mask\n",
    "        )  # shape: (batch_size, tgt_seq_len, d_model)\n",
    "\n",
    "        # 6) 최종 Dense (vocab_size)\n",
    "        logits = self.final_linear(dec_outputs)  # (batch_size, tgt_seq_len, vocab_size)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e1e75041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Embedding(12000, 512)\n",
      "    (pos_encoding): PositionalEncoding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (enc_layers): ModuleList(\n",
      "      (0-2): 3 x EncoderLayer(\n",
      "        (mha): MultiHeadAttention(\n",
      "          (query_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (key_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (value_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (embedding): Embedding(12000, 512)\n",
      "    (pos_encoding): PositionalEncoding()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (dec_layers): ModuleList(\n",
      "      (0-2): 3 x DecoderLayer(\n",
      "        (self_mha): MultiHeadAttention(\n",
      "          (query_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (key_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (value_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (encdec_mha): MultiHeadAttention(\n",
      "          (query_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (key_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (value_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (out_dense): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (ffn): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (1): ReLU()\n",
      "          (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (norm3): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (final_linear): Linear(in_features=512, out_features=12000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 예: 하이퍼파라미터 설정\n",
    "NUM_LAYERS = 3     # 인코더/디코더 층 수\n",
    "D_MODEL = 512      # 임베딩 및 내부 표현 차원\n",
    "NUM_HEADS = 8      # 멀티헤드 어텐션에서의 헤드 수\n",
    "UNITS = 512        # 피드포워드 신경망의 은닉 차원\n",
    "DROPOUT = 0.1      # 드롭아웃 비율\n",
    "VOCAB_SIZE = vocab_size # 단어 집합 크기(예시)\n",
    "BATCH_SIZE = 512\n",
    "dataset = KoDataset(zip(data[\"Q\"], data[\"A\"]), sp, max_length=80)\n",
    "dataloader = DataLoader(dataset,batch_size=BATCH_SIZE,shuffle=True)\n",
    "# 모델 생성\n",
    "model = Transformer(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    num_layers=NUM_LAYERS,\n",
    "    units=UNITS,\n",
    "    d_model=D_MODEL,\n",
    "    num_heads=NUM_HEADS,\n",
    "    dropout=DROPOUT\n",
    ")\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78f70608",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss(ignore_index=sp.pad_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73ba4446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_lambda(d_model, warmup_steps=4000):\n",
    "    d_model = float(d_model)\n",
    "    def lr_lambda(step):\n",
    "        # step은 0부터 시작하므로 +1로 보정\n",
    "        step = step + 1\n",
    "        return (d_model ** -0.5) * min(step ** -0.5, step * (warmup_steps ** -1.5))\n",
    "    return lr_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34e81fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "warmup_steps = 4000\n",
    "total_steps = 200000  # 총 학습 스텝\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c12e3a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer 정의\n",
    "optimizer = optim.Adam(model.parameters(), betas=(0.9, 0.98), eps=1e-9, lr=2e-3)\n",
    "\n",
    "# Scheduler 정의\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=get_lr_lambda(D_MODEL, warmup_steps=10))\n",
    "\n",
    "def accuracy_function(y_pred, y_true, pad_id=0):\n",
    "    \"\"\"\n",
    "    y_pred: (batch_size, seq_len, vocab_size)\n",
    "    y_true: (batch_size, seq_len)\n",
    "    \"\"\"\n",
    "    preds = y_pred.argmax(dim=-1)  # (batch_size, seq_len)\n",
    "    mask = (y_true != pad_id)\n",
    "    correct = (preds == y_true) & mask\n",
    "    acc = correct.float().sum() / mask.float().sum()\n",
    "    return acc\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d25982f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, batch, optimizer, loss_function, device):\n",
    "    model.train()\n",
    "    enc_input, dec_input, target = [x.to(device) for x in batch]\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 모델 포워드 패스\n",
    "    logits = model(enc_input, dec_input)  # (batch_size, seq_len, vocab_size)\n",
    "\n",
    "    # Loss 계산 (패딩 토큰 무시)\n",
    "    loss = loss_function(logits.permute(0, 2, 1), target)  # (batch_size, vocab_size, seq_len) 필요\n",
    "\n",
    "    # Backpropagation\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return loss.item(), accuracy_function(logits, target, pad_id=sp.pad_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "03402069",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer, loss_function, scheduler, num_epochs, device):\n",
    "    model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss, total_acc = 0, 0\n",
    "        for step, batch in enumerate(dataloader):\n",
    "            loss, acc = train_step(model, batch, optimizer, loss_function, device)\n",
    "            total_loss += loss\n",
    "            total_acc += acc\n",
    "\n",
    "            # 일정 스텝마다 로그 출력\n",
    "            if step % 100 == 0:\n",
    "                print(f\"[Epoch {epoch+1}, Step {step}] Loss: {loss:.4f}, Acc: {acc:.4f}\")\n",
    "\n",
    "            # 학습률 스케줄러 업데이트\n",
    "            scheduler.step()\n",
    "\n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        avg_acc = total_acc / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1} Completed - Avg Loss: {avg_loss:.4f}, Avg Acc: {avg_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b21fbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Step 0] Loss: 9.5197, Acc: 0.0000\n",
      "Epoch 1 Completed - Avg Loss: 8.8506, Avg Acc: 0.1180\n",
      "[Epoch 2, Step 0] Loss: 8.1604, Acc: 0.1889\n",
      "Epoch 2 Completed - Avg Loss: 8.0579, Avg Acc: 0.1871\n",
      "[Epoch 3, Step 0] Loss: 7.8811, Acc: 0.1949\n",
      "Epoch 3 Completed - Avg Loss: 7.8797, Avg Acc: 0.1866\n",
      "[Epoch 4, Step 0] Loss: 7.8059, Acc: 0.1846\n",
      "Epoch 4 Completed - Avg Loss: 7.7585, Avg Acc: 0.1873\n",
      "[Epoch 5, Step 0] Loss: 7.6807, Acc: 0.1893\n",
      "Epoch 5 Completed - Avg Loss: 7.6816, Avg Acc: 0.1865\n",
      "[Epoch 6, Step 0] Loss: 7.5941, Acc: 0.1947\n",
      "Epoch 6 Completed - Avg Loss: 7.6149, Avg Acc: 0.1861\n",
      "[Epoch 7, Step 0] Loss: 7.6383, Acc: 0.1836\n",
      "Epoch 7 Completed - Avg Loss: 7.5535, Avg Acc: 0.1868\n",
      "[Epoch 8, Step 0] Loss: 7.4913, Acc: 0.1908\n",
      "Epoch 8 Completed - Avg Loss: 7.5008, Avg Acc: 0.1864\n",
      "[Epoch 9, Step 0] Loss: 7.4543, Acc: 0.1903\n",
      "Epoch 9 Completed - Avg Loss: 7.4476, Avg Acc: 0.1869\n",
      "[Epoch 10, Step 0] Loss: 7.4658, Acc: 0.1860\n"
     ]
    }
   ],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    dataloader=dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss_function,\n",
    "    scheduler=scheduler,\n",
    "    num_epochs=500,  # 원하는 에폭 수\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a82352c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_inference(model, sentence, tokenizer, device='cpu'):\n",
    "    START_TOKEN = tokenizer.bos_id()\n",
    "    END_TOKEN = tokenizer.eos_id()\n",
    "    MAX_LENGTH = 40\n",
    "\n",
    "\n",
    "    # 전처리\n",
    "    sentence = clean_korean(sentence)\n",
    "\n",
    "    # 인코더 입력: [START] + 인코딩 + [END]\n",
    "    enc_input_ids = [START_TOKEN] + tokenizer.encode(sentence) + [END_TOKEN]\n",
    "    # 차원 확장: (batch_size=1, seq_len)\n",
    "    enc_input = torch.tensor([enc_input_ids], dtype=torch.long, device=device)\n",
    "\n",
    "    # 디코더 입력(dec_input)을 START_TOKEN만 포함한 상태로 시작\n",
    "    dec_input = torch.tensor([[START_TOKEN]], dtype=torch.long, device=device)\n",
    "\n",
    "    model.eval()  # 모델 평가 모드\n",
    "    with torch.no_grad():\n",
    "        for i in range(MAX_LENGTH):\n",
    "            # 모델 forward: (enc_input, dec_input) -> (batch_size=1, seq_len, vocab_size)\n",
    "            logits = model(enc_input, dec_input)\n",
    "\n",
    "            # 마지막 타임스텝의 예측만 추출: shape (1, 1, vocab_size)\n",
    "            # logits[:, -1, :] -> (1, vocab_size)\n",
    "            last_step_logits = logits[:, -1, :]\n",
    "\n",
    "            # argmax로 가장 높은 확률의 토큰 선택\n",
    "            predicted_id = torch.argmax(last_step_logits, dim=-1)  # shape: (1,)\n",
    "\n",
    "            # 종료 토큰이면 중단\n",
    "            if predicted_id.item() == END_TOKEN:\n",
    "                break\n",
    "\n",
    "            # 디코더 입력(dec_input)에 예측 토큰을 이어붙임\n",
    "            predicted_id = predicted_id.unsqueeze(0)  # shape (1,1)\n",
    "            dec_input = torch.cat([dec_input, predicted_id], dim=1)\n",
    "\n",
    "    # 최종 시퀀스: dec_input: (1, seq_len)에서 (seq_len,)로\n",
    "    output_sequence = dec_input.squeeze(0).tolist()  # e.g. [START_TOKEN, ..., 토큰들...]\n",
    "\n",
    "    return output_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee74fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, sentence, tokenizer, device='cpu'):\n",
    "    # 디코더 인퍼런스 -> 예측된 토큰 시퀀스\n",
    "    output_seq = decoder_inference(model, sentence, tokenizer, device=device)\n",
    "\n",
    "    # 토크나이저로 디코딩 (패딩, START/END 토큰 등은 제외하거나 처리)\n",
    "    # 여기서는 단순히 tokenizer.decode() 직접 호출\n",
    "    predicted_sentence = tokenizer.decode(\n",
    "        [token for token in output_seq if token < tokenizer.GetPieceSize()]\n",
    "    )\n",
    "\n",
    "    print(\"입력 :\", sentence)\n",
    "    print(\"출력 :\", predicted_sentence)\n",
    "    return predicted_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363a7979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 : Where have you been?\n",
      "출력 : \n",
      "입력 : It's a trap\n",
      "출력 : \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = 'Where have you been?'\n",
    "sentence_generation(model, sentence, sp, device)\n",
    "\n",
    "sentence = \"It's a trap\"\n",
    "sentence_generation(model, sentence, sp, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
