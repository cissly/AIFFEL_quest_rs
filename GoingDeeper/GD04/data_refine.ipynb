{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc1fb48f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.0+cu128\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import os, cv2, time\n",
    "import tqdm\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "import pickle\n",
    "\n",
    "PROJECT_PATH = '.'\n",
    "DATA_PATH = os.path.join(PROJECT_PATH, 'datas')\n",
    "MODEL_PATH = os.path.join(PROJECT_PATH, 'checkpoints')\n",
    "TRAIN_PT_PATH = os.path.join(PROJECT_PATH, 'datas', 'train_data.pt')\n",
    "VALID_PT_PATH = os.path.join(PROJECT_PATH, 'datas', 'val_data.pt')\n",
    "CHECKPOINT_PATH = os.path.join(PROJECT_PATH, 'checkpoints')\n",
    "\n",
    "DATASET_LEN = 12880\n",
    "BATCH_SIZE = 8\n",
    "IMAGE_WIDTH = 320\n",
    "IMAGE_HEIGHT = 256\n",
    "IMAGE_LABELS = ['background', 'face']\n",
    "\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce7489e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def parse_box(data):\n",
    "    x0 = int(data[0])\n",
    "    y0 = int(data[1])\n",
    "    w = int(data[2])\n",
    "    h = int(data[3])\n",
    "    return x0, y0, w, h\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04c522c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def parse_widerface(file):\n",
    "    infos = []\n",
    "    with open(file) as fp:\n",
    "        line = fp.readline()\n",
    "        while line:\n",
    "            n_object = int(fp.readline())\n",
    "            boxes = []\n",
    "            for i in range(n_object):\n",
    "                box = fp.readline().split(' ')\n",
    "                x0, y0, w, h = parse_box(box)\n",
    "                if (w == 0) or (h == 0):\n",
    "                    continue\n",
    "                boxes.append([x0, y0, w, h])\n",
    "            if n_object == 0:\n",
    "                box = fp.readline().split(' ')\n",
    "                x0, y0, w, h = parse_box(box)\n",
    "                boxes.append([x0, y0, w, h])\n",
    "            infos.append((line.strip(), boxes))\n",
    "            line = fp.readline()\n",
    "    return infos\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe070346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def process_image(image_file):\n",
    "    try:\n",
    "        with open(image_file, 'rb') as f:\n",
    "            image_string = f.read()\n",
    "            image_data = Image.open(io.BytesIO(image_string)).convert('RGB')\n",
    "            image_data = torch.from_numpy(np.array(image_data)).permute(2, 0, 1)  # HWC to CHW\n",
    "            return 0, image_string, image_data\n",
    "    except Exception as e:\n",
    "        return 1, image_string, None\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a472f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "def xywh_to_voc(file_name, boxes, image_data):\n",
    "    shape = image_data.shape\n",
    "    image_info = {}\n",
    "    image_info['filename'] = file_name\n",
    "    image_info['width'] = shape[1]\n",
    "    image_info['height'] = shape[0]\n",
    "    image_info['depth'] = 3\n",
    "\n",
    "    difficult = []\n",
    "    classes = []\n",
    "    xmin, ymin, xmax, ymax = [], [], [], []\n",
    "\n",
    "    for box in boxes:\n",
    "        classes.append(1)\n",
    "        difficult.append(0)\n",
    "        xmin.append(box[0])\n",
    "        ymin.append(box[1])\n",
    "        xmax.append(box[0] + box[2])\n",
    "        ymax.append(box[1] + box[3])\n",
    "    image_info['class'] = classes\n",
    "    image_info['xmin'] = xmin\n",
    "    image_info['ymin'] = ymin\n",
    "    image_info['xmax'] = xmax\n",
    "    image_info['ymax'] = ymax\n",
    "    image_info['difficult'] = difficult\n",
    "\n",
    "    return image_info\n",
    "\n",
    "print('슝=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "226c2812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "{'filename': '.\\\\datas\\\\WIDER_train\\\\images\\\\0--Parade/0_Parade_marchingband_1_849.jpg', 'width': 1385, 'height': 3, 'depth': 3, 'class': [1], 'xmin': [449], 'ymin': [330], 'xmax': [571], 'ymax': [479], 'difficult': [0]}\n",
      "--------------------\n",
      "{'filename': '.\\\\datas\\\\WIDER_train\\\\images\\\\0--Parade/0_Parade_Parade_0_904.jpg', 'width': 1432, 'height': 3, 'depth': 3, 'class': [1], 'xmin': [361], 'ymin': [98], 'xmax': [624], 'ymax': [437], 'difficult': [0]}\n",
      "--------------------\n",
      "{'filename': '.\\\\datas\\\\WIDER_train\\\\images\\\\0--Parade/0_Parade_marchingband_1_799.jpg', 'width': 768, 'height': 3, 'depth': 3, 'class': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'xmin': [78, 78, 113, 134, 163, 201, 182, 245, 304, 328, 389, 406, 436, 522, 643, 653, 793, 535, 29, 3, 20], 'ymin': [221, 238, 212, 260, 250, 218, 266, 279, 265, 295, 281, 293, 290, 328, 320, 224, 337, 311, 220, 232, 215], 'xmax': [85, 92, 124, 149, 177, 211, 197, 263, 320, 344, 406, 427, 458, 543, 666, 670, 816, 551, 40, 14, 32], 'ymax': [229, 255, 227, 275, 267, 230, 283, 294, 282, 315, 300, 314, 307, 346, 342, 249, 367, 328, 235, 247, 231], 'difficult': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "--------------------\n",
      "{'filename': '.\\\\datas\\\\WIDER_train\\\\images\\\\0--Parade/0_Parade_marchingband_1_117.jpg', 'width': 682, 'height': 3, 'depth': 3, 'class': [1, 1, 1, 1, 1, 1, 1, 1, 1], 'xmin': [69, 227, 296, 353, 885, 819, 727, 598, 740], 'ymin': [359, 382, 305, 280, 377, 391, 342, 246, 308], 'xmax': [119, 283, 340, 393, 948, 853, 764, 631, 785], 'ymax': [395, 425, 331, 316, 418, 434, 373, 275, 341], 'difficult': [0, 0, 0, 0, 0, 0, 0, 0, 0]}\n",
      "--------------------\n",
      "{'filename': '.\\\\datas\\\\WIDER_train\\\\images\\\\0--Parade/0_Parade_marchingband_1_778.jpg', 'width': 852, 'height': 3, 'depth': 3, 'class': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'xmin': [27, 63, 64, 88, 231, 263, 367, 198, 293, 412, 441, 475, 510, 576, 577, 595, 570, 645, 719, 791, 884, 898, 945, 922, 743, 841, 980, 1001, 488, 586, 669, 744, 803, 294, 203], 'ymin': [226, 95, 63, 13, 1, 122, 68, 98, 161, 36, 23, 40, 23, 30, 71, 94, 126, 171, 98, 154, 97, 48, 89, 38, 71, 18, 56, 107, 2, 1, 1, 2, 3, 2, 0], 'xmax': [60, 79, 81, 104, 244, 277, 382, 213, 345, 426, 458, 489, 524, 592, 593, 611, 583, 697, 730, 845, 900, 913, 960, 937, 754, 857, 993, 1015, 500, 601, 681, 762, 821, 305, 216], 'ymax': [262, 114, 81, 28, 14, 142, 91, 116, 220, 56, 36, 61, 40, 45, 92, 114, 142, 229, 113, 203, 118, 69, 109, 54, 89, 34, 76, 120, 20, 18, 16, 17, 20, 12, 14], 'difficult': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "file_path = os.path.join(DATA_PATH, 'wider_face_split', 'wider_face_train_bbx_gt.txt')\n",
    "for i, info in enumerate(parse_widerface(file_path)):\n",
    "    print('--------------------')\n",
    "    image_file = os.path.join(DATA_PATH, 'WIDER_train', 'images', info[0])\n",
    "    _, image_string, image_data = process_image(image_file)\n",
    "    boxes = xywh_to_voc(image_file, info[1], image_data)\n",
    "    print(boxes)\n",
    "    if i > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fae4924",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "def make_example(image_string, image_infos):\n",
    "    for info in image_infos:\n",
    "        filename = info['filename']\n",
    "        width = info['width']\n",
    "        height = info['height']\n",
    "        depth = info['depth']\n",
    "        classes = info['class']\n",
    "        xmin = info['xmin']\n",
    "        ymin = info['ymin']\n",
    "        xmax = info['xmax']\n",
    "        ymax = info['ymax']\n",
    "\n",
    "    # 이미지 데이터를 numpy 배열로 변환\n",
    "    image_data = np.frombuffer(image_string, dtype=np.uint8)\n",
    "    image_data = Image.open(io.BytesIO(image_data)).convert('RGB')\n",
    "    image_data = np.array(image_data)\n",
    "\n",
    "    # 데이터를 dict 형태로 저장\n",
    "    example = {\n",
    "        'filename': filename,\n",
    "        'height': height,\n",
    "        'width': width,\n",
    "        'classes': classes,\n",
    "        'xmin': xmin,\n",
    "        'ymin': ymin,\n",
    "        'xmax': xmax,\n",
    "        'ymax': ymax,\n",
    "        'image_raw': image_data\n",
    "    }\n",
    "\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7aa8e124",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10681/12880 [02:02<00:25, 86.88it/s]\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 2.84 MiB for an array with shape (968, 1024, 3) and data type uint8",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     21\u001b[39m     boxes = xywh_to_voc(image_file, info[\u001b[32m1\u001b[39m], image_data)\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m error:\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m         example = \u001b[43mmake_example\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_string\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mboxes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m         dataset.append(example)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# dataset을 .pt 파일로 저장\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# torch.save(dataset, output_file)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mmake_example\u001b[39m\u001b[34m(image_string, image_infos)\u001b[39m\n\u001b[32m     16\u001b[39m image_data = np.frombuffer(image_string, dtype=np.uint8)\n\u001b[32m     17\u001b[39m image_data = Image.open(io.BytesIO(image_data)).convert(\u001b[33m'\u001b[39m\u001b[33mRGB\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m image_data = np.array(image_data)\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# 데이터를 dict 형태로 저장\u001b[39;00m\n\u001b[32m     21\u001b[39m example = {\n\u001b[32m     22\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfilename\u001b[39m\u001b[33m'\u001b[39m: filename,\n\u001b[32m     23\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mheight\u001b[39m\u001b[33m'\u001b[39m: height,\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mimage_raw\u001b[39m\u001b[33m'\u001b[39m: image_data\n\u001b[32m     31\u001b[39m }\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 2.84 MiB for an array with shape (968, 1024, 3) and data type uint8"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "for split in ['train']:\n",
    "    if split == 'train':\n",
    "        output_file = TRAIN_PT_PATH\n",
    "        anno_txt = 'wider_face_train_bbx_gt.txt'\n",
    "        file_path = 'WIDER_train'\n",
    "    else:\n",
    "        output_file = VALID_PT_PATH\n",
    "        anno_txt = 'wider_face_val_bbx_gt.txt'\n",
    "        file_path = 'WIDER_val'\n",
    "\n",
    "    dataset = []  # 데이터를 저장할 리스트\n",
    "\n",
    "    for info in tqdm.tqdm(parse_widerface(os.path.join(DATA_PATH, 'wider_face_split', anno_txt))):\n",
    "        image_file = os.path.join(DATA_PATH, file_path, 'images', info[0])\n",
    "        error, image_string, image_data = process_image(image_file)\n",
    "        boxes = xywh_to_voc(image_file, info[1], image_data)\n",
    "\n",
    "        if not error:\n",
    "            example = make_example(image_string, [boxes])\n",
    "            dataset.append(example)\n",
    "\n",
    "    # dataset을 .pt 파일로 저장\n",
    "    # torch.save(dataset, output_file)\n",
    "    print(\"done\")\n",
    "\n",
    "print('슝=3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
