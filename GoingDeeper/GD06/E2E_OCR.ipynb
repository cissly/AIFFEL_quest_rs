{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94c71c53",
   "metadata": {},
   "source": [
    "로컬 환경에서 keras-ocr을 이용하여 detector를 가져오려고 하였으나 tensorflow를 요구함 tensorflow를 gpu상에 구현하기에는 시간이 오래걸려 cpu만 사용하는 버전을 사용하려고 하였으나 AMD cpu에 지원에 오류가 있는 현상이 있어 easyocr의 detection된 결과를 이용하고자 함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46ea99f",
   "metadata": {},
   "source": [
    "최종적으로 E2E_OCR_process 함수를 만들었다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cf28389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import easyocr\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 1) EasyOCR Detector 역할 (Reader)\n",
    "reader = easyocr.Reader(['en'])  # 필요한 언어 추가 가능: ['en', 'ko'] 등\n",
    "SAMPLE_IMG_PATH = \"C:\\\\Users\\\\tkdwl\\\\AIFFEL_quest_rs\\\\GoingDeeper\\\\GD06\\\\datas\\\\sample.png\"\n",
    "NUMBERS = \"0123456789\"\n",
    "ENG_CHAR_UPPER = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n",
    "TARGET_CHARACTERS = ENG_CHAR_UPPER + NUMBERS\n",
    "\n",
    "def detect_text(img_path):\n",
    "    # PIL로 이미지 열기\n",
    "    img_pil = Image.open(img_path).convert('RGB')\n",
    "    # EasyOCR은 numpy 배열을 입력받으므로 변환\n",
    "    img_np = np.array(img_pil)\n",
    "\n",
    "    # EasyOCR을 이용한 텍스트 검출 및 인식\n",
    "    # 결과 형식: [(bbox, text, confidence), ...]\n",
    "    ocr_result = reader.readtext(img_np)\n",
    "\n",
    "    # 시각화를 위해 ImageDraw 객체 생성\n",
    "    img_draw = ImageDraw.Draw(img_pil)\n",
    "    cropped_imgs = []\n",
    "\n",
    "    for bbox, text, conf in ocr_result:\n",
    "        # 좌표를 정수형으로 변환\n",
    "        bbox_int = [(int(x), int(y)) for x, y in bbox]\n",
    "        img_draw.polygon(bbox_int, outline='red')\n",
    "\n",
    "        xs = [pt[0] for pt in bbox_int]\n",
    "        ys = [pt[1] for pt in bbox_int]\n",
    "        x_min = max(0, min(xs) - 5)\n",
    "        y_min = max(0, min(ys) - 5)\n",
    "        x_max = max(xs) + 5\n",
    "        y_max = max(ys) + 5\n",
    "        word_box = (x_min, y_min, x_max, y_max)\n",
    "        cropped_imgs.append(img_pil.crop(word_box))\n",
    "\n",
    "    return img_pil, cropped_imgs, ocr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aea1f122",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelConverter(object):\n",
    "\n",
    "     def __init__(self, character):\n",
    "         self.character = \"-\" + character\n",
    "         self.label_map = dict()\n",
    "         for i, char in enumerate(self.character):\n",
    "             self.label_map[char] = i\n",
    "\n",
    "     def encode(self, text):\n",
    "         encoded_label = []\n",
    "         for i, char in enumerate(text):\n",
    "             if i > 0 and char == text[i - 1]:\n",
    "                 encoded_label.append(0)    # 같은 문자 사이에 공백 문자 label을 삽입\n",
    "             encoded_label.append(self.label_map[char])\n",
    "         return np.array(encoded_label, dtype=np.int32)\n",
    "\n",
    "     def decode(self, encoded_label):\n",
    "         target_characters = list(self.character)\n",
    "         decoded_label = \"\"\n",
    "         for encode in encoded_label:\n",
    "             decoded_label += self.character[encode]\n",
    "         return decoded_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dc1dde15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "    def __init__(self, num_chars, img_height=32, img_width=100):\n",
    "        super(CRNN, self).__init__()\n",
    "        # num_chars: 실제 문자 개수(+2) -> 여기서는 +2(CTC Blank 등)를\n",
    "        # LabelConverter에서 이미 blank를 붙여줬으니,\n",
    "        # 파이토치의 CTCLoss는 blank 인덱스를 지정 가능하므로, +2 없이 설계할 수 있음.\n",
    "        # 여기서는 blank를 0번으로 하므로 굳이 +2가 필요 없을 수 있습니다.\n",
    "        # 필요시엔 +1 혹은 +2로 조정하세요.\n",
    "        self.num_chars = num_chars\n",
    "\n",
    "        # (3, H, W) -> (64, H, W)\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)  # (64, H/2, W/2)\n",
    "\n",
    "        # (64, H/2, W/2) -> (128, H/2, W/2)\n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)  # (128, H/4, W/4)\n",
    "\n",
    "        # (128, H/4, W/4) -> (256, H/4, W/4)\n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d((1, 2))  # (256, H/4, W/8)\n",
    "\n",
    "        # (256, H/4, W/8) -> (512, H/4, W/8)\n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.conv6 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(512)\n",
    "        self.pool4 = nn.MaxPool2d((1, 2))  # (512, H/4, W/16)\n",
    "\n",
    "        # (512, H/4, W/16) -> (512, (H/4)-1, (W/16)-1) conv(2,2)\n",
    "        self.conv7 = nn.Conv2d(512, 512, kernel_size=(2, 2))\n",
    "        # 최종 (512, (H/4)-1, (W/16)-1)\n",
    "        # 예) H=32 -> H/4=8 -> (8)-1=7\n",
    "        #     W=100 -> W/16=6.25 -> 실제 integer shape는 계산 필요\n",
    "        # 텐서플로우 예시에선 (24, 512) 시퀀스로 reshape했으니, 여기선 실제 연산으로 확인 필요\n",
    "\n",
    "        # Bi-LSTM\n",
    "        self.lstm1 = nn.LSTM(512, 256, bidirectional=True, batch_first=True)\n",
    "        self.lstm2 = nn.LSTM(512, 256, bidirectional=True, batch_first=True)\n",
    "\n",
    "        # 최종 fc\n",
    "        self.fc = nn.Linear(512, self.num_chars)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # (B,3,32,100)\n",
    "        x = F.relu(self.conv1(x))      # -> (B,64,32,100)\n",
    "        x = self.pool1(x)             # -> (B,64,16,50)\n",
    "        x = F.relu(self.conv2(x))      # -> (B,128,16,50)\n",
    "        x = self.pool2(x)             # -> (B,128,8,25)\n",
    "        x = F.relu(self.conv3(x))      # -> (B,256,8,25)\n",
    "        x = F.relu(self.conv4(x))      # -> (B,256,8,25)\n",
    "        x = self.pool3(x)             # -> (B,256,8,12) (25->12)\n",
    "        x = F.relu(self.conv5(x))      # -> (B,512,8,12)\n",
    "        x = self.bn5(x)\n",
    "        x = F.relu(self.conv6(x))      # -> (B,512,8,12)\n",
    "        x = self.bn6(x)\n",
    "        x = self.pool4(x)             # -> (B,512,8,6)\n",
    "        x = F.relu(self.conv7(x))      # -> (B,512,7,5) (8->7, 6->5)\n",
    "\n",
    "        b, c, h, w = x.size()\n",
    "        # 시퀀스 길이 = h*w\n",
    "        x = x.view(b, c, h * w)  # (B,512,35)\n",
    "        x = x.permute(0, 2, 1)   # (B,35,512)\n",
    "\n",
    "        # LSTM\n",
    "        x, _ = self.lstm1(x)    # (B,35,512)\n",
    "        x, _ = self.lstm2(x)    # (B,35,512)\n",
    "\n",
    "        # 최종 FC\n",
    "        x = self.fc(x)          # (B,35,num_chars)\n",
    "\n",
    "        # PyTorch의 CTCLoss를 위해선 (T,B,C) 형태가 일반적\n",
    "        # 여기서는 (B,T,C) -> (T,B,C)\n",
    "        x = x.permute(1, 0, 2)  # (35,B,num_chars)\n",
    "        return x\n",
    "\n",
    "class LabelConverter(object):\n",
    "\n",
    "     def __init__(self, character):\n",
    "         self.character = \"-\" + character\n",
    "         self.label_map = dict()\n",
    "         for i, char in enumerate(self.character):\n",
    "             self.label_map[char] = i\n",
    "\n",
    "     def encode(self, text):\n",
    "         encoded_label = []\n",
    "         for i, char in enumerate(text):\n",
    "             if i > 0 and char == text[i - 1]:\n",
    "                 encoded_label.append(0)    # 같은 문자 사이에 공백 문자 label을 삽입\n",
    "             encoded_label.append(self.label_map[char])\n",
    "         return np.array(encoded_label, dtype=np.int32)\n",
    "\n",
    "     def decode(self, encoded_label):\n",
    "         target_characters = list(self.character)\n",
    "         decoded_label = \"\"\n",
    "         for encode in encoded_label:\n",
    "             decoded_label += self.character[encode]\n",
    "         return decoded_label\n",
    "         \n",
    "def decode_greedy(output, label_converter):\n",
    "    # (T,B,C) -> (B,T) index\n",
    "    out = output.detach().cpu().numpy()  # (T,B,C)\n",
    "    argmax = out.argmax(axis=2).transpose()  # (B,T)\n",
    "\n",
    "    results = []\n",
    "    for seq in argmax:\n",
    "        # 연속된 동일 글자(또는 blank=0) 제거 로직을 적용해야\n",
    "        # CTC 디코딩다운 결과가 나옵니다.\n",
    "        # 여기서는 간단히 blank(0) 무시하고 연속 제거만 보여줌\n",
    "        decoded = []\n",
    "        prev = None\n",
    "        for idx in seq:\n",
    "            if idx != 0 and idx != prev:\n",
    "                decoded.append(idx)\n",
    "            prev = idx\n",
    "        # 인덱스를 실제 문자로\n",
    "        decoded_str = label_converter.decode(decoded).replace('-', '')\n",
    "        results.append(decoded_str)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32741c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool3): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool4): MaxPool2d(kernel_size=(1, 2), stride=(1, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv7): Conv2d(512, 512, kernel_size=(2, 2), stride=(1, 1))\n",
       "  (lstm1): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
       "  (lstm2): LSTM(512, 256, batch_first=True, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=37, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "checkpoint_path = \"C:\\\\Users\\\\tkdwl\\\\AIFFEL_quest_rs\\\\GoingDeeper\\\\GD06\\\\datas\\\\model_checkpoint.pth\"\n",
    "label_converter = LabelConverter(TARGET_CHARACTERS)\n",
    "model = CRNN(num_chars=37).to(device)\n",
    "model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9cf6564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_img(pil_img, input_img_size=(100, 32)):\n",
    "    \"\"\"\n",
    "    잘려진 단어 이미지를 CRNN으로 인식하는 함수.\n",
    "    pil_img : 단어 영역이 잘려진 PIL.Image\n",
    "    input_img_size : (W, H) = (100, 32) 형태 (학습 때 쓴 사이즈와 동일해야 함)\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. PIL -> RGB numpy\n",
    "    pil_img = pil_img.convert('RGB')\n",
    "    img_np = np.array(pil_img)  # (H, W, 3)\n",
    "\n",
    "    # 2. 인식 모델 입력 크기에 맞게 resize\n",
    "    #    cv2.resize는 (width, height) 순서이므로 (W, H) 그대로 넣음\n",
    "    img_resized = cv2.resize(img_np, input_img_size)  # (H', W', 3)가 아니라 (W, H)로 맞춰줌\n",
    "\n",
    "    # 3. [0,1] 스케일로 정규화 (학습 때 normalize를 다르게 했다면 여기 맞춰서 수정)\n",
    "    img_resized = img_resized.astype(np.float32) / 255.0\n",
    "\n",
    "    # 4. (H, W, C) -> (C, H, W)\n",
    "    img_chw = np.transpose(img_resized, (2, 0, 1))  # (3, H, W)\n",
    "\n",
    "    # 5. 배치 차원 추가 후 텐서로 변환\n",
    "    img_tensor = torch.from_numpy(img_chw).unsqueeze(0).to(device)  # (1, 3, H, W)\n",
    "\n",
    "    # 6. CRNN 모델로 인퍼런스\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(img_tensor)  # (T, B=1, num_chars)\n",
    "\n",
    "    # 7. CTC greedy 디코딩\n",
    "    recognized_text = decode_greedy(output, label_converter)[0]\n",
    "\n",
    "    print(\"Recognized text:\", recognized_text)\n",
    "    return recognized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37763b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def E2E_OCR_process(path):\n",
    "    img_pil, cropped_imgs, ocr_result = detect_text(path)\n",
    "    for idx, word_img in enumerate(cropped_imgs):\n",
    "        print(f\"[{idx}] \", end=\"\")\n",
    "        result = recognize_img(word_img)\n",
    "    return img_pil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "550b080f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SAMPLE_IMG_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m E2E_OCR_process(\u001b[43mSAMPLE_IMG_PATH\u001b[49m)\n",
      "\u001b[31mNameError\u001b[39m: name 'SAMPLE_IMG_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "E2E_OCR_process(SAMPLE_IMG_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiffel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
